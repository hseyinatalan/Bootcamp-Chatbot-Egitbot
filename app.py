import os
import datetime
import gradio as gr
from datasets import load_dataset
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.text_splitter import TokenTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI

# Cache klasÃ¶r ayarlarÄ±
os.environ["HF_HOME"] = "./cache"
os.environ["HF_DATASETS_CACHE"] = "./cache/hf_datasets"
os.environ["TRANSFORMERS_CACHE"] = "./cache/transformers"
os.environ["SENTENCE_TRANSFORMERS_HOME"] = "./cache/sentence_transformers"

# API anahtarlarÄ± ortam deÄŸiÅŸkenlerinden alÄ±nmalÄ±
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
HUGGINGFACEHUB_API_TOKEN = os.getenv("HUGGINGFACEHUB_API_TOKEN")
MODEL_NAME = "models/gemini-2.5-pro"

# Veri hazÄ±rlama fonksiyonu (aynÄ±)
def prepare_retriever():
    dataset_math_word = load_dataset("duxx/orca-math-word-problems-tr", split="train[:2000]")
    dataset_math_hard = load_dataset("Karayel-DDI/Turkce_Lighteval_MATH-Hard", split="train[:2000]")
    dataset_edu = load_dataset("korkmazemin1/turkish-education-dataset", split="train[:2000]")
    dataset_wiki_sum = load_dataset("musabg/wikipedia-tr-summarization", split="train[:2000]")

    documents = []
    for item in dataset_math_word:
        question = item.get("question", "").strip()
        answer = item.get("answer", "").strip()
        if question and answer:
            documents.append(f"Soru: {question}\nCevap: {answer}")

    for item in dataset_math_hard:
        question = item.get("question", "").strip()
        answer = item.get("solution", "").strip()
        if question and answer:
            documents.append(f"Soru: {question}\nCevap: {answer}")

    for item in dataset_edu:
        question = item.get("soru", "").strip()
        answer = item.get("cevap", "").strip()
        if question and answer:
            documents.append(f"Soru: {question}\nCevap: {answer}")

    for item in dataset_wiki_sum:
        text = item.get("text", "").strip()
        summary = item.get("summary", "").strip()
        if text and summary:
            documents.append(f"Metin: {text}\nÃ–zet: {summary}")

    text_splitter = TokenTextSplitter(chunk_size=1000, chunk_overlap=100)
    docs = text_splitter.create_documents(documents)

    embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

    FAISS_PATH = "faiss_index"
    if os.path.exists(FAISS_PATH):
        vectorstore = FAISS.load_local(FAISS_PATH, embedding_model, allow_dangerous_deserialization=True)
    else:
        vectorstore = FAISS.from_documents(docs, embedding_model)
        vectorstore.save_local(FAISS_PATH)

    return vectorstore.as_retriever(search_kwargs={"k": 3})

retriever = prepare_retriever()

prompt_template = """
Sadece sorulan soruya net ve kÄ±sa cevap ver. Gereksiz ek aÃ§Ä±klama yapma. 
Sadece yukarÄ±daki soruya cevap ver. BaÅŸka konulara girmeyin veya yeni sorular sormayÄ±n.

Bilgiler:
{context}

Soru:
{question}

Cevap:
"""

PROMPT = PromptTemplate(
    template=prompt_template,
    input_variables=["context", "question"]
)

llm = ChatGoogleGenerativeAI(
    model=MODEL_NAME,
    google_api_key=GOOGLE_API_KEY
)

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    return_source_documents=False,
    chain_type="stuff",
    chain_type_kwargs={"prompt": PROMPT}
)

# Gradio UI dÃ¼zeni
with gr.Blocks() as demo:
    gr.Markdown("# ğŸ“˜ EÄŸitBot - EÄŸitim AsistanÄ±")
    
    with gr.Row():
        with gr.Column(scale=2):
            # Soru sorma alanÄ±
            user_input = gr.Textbox(placeholder="Sorunuzu buraya yazÄ±nÄ±z...", label="Soru")
            send_btn = gr.Button("GÃ¶nder")

            # Toplam soru sayÄ±sÄ±
            total_q = gr.Number(value=0, label="Toplam Sorulan Soru", interactive=False)

            # Sohbet geÃ§miÅŸi
            chatbox = gr.HTML(value="", label="Sohbet GeÃ§miÅŸi")

        with gr.Column(scale=1):
            # Sohbeti kaydetme ve temizleme butonlarÄ±
            clear_btn = gr.Button("â™»ï¸ GeÃ§miÅŸi Temizle", variant="primary")
            save_btn = gr.Button("ğŸ’¾ Sohbeti Kaydet", variant="primary")
            download_file = gr.File(label="Ä°ndir")

    # Sohbeti temizleme fonksiyonu
    def clear_chat():
        return "", 0  # Sohbeti temizle ve sorularÄ± sÄ±fÄ±rla

    clear_btn.click(fn=clear_chat, inputs=[], outputs=[chatbox, total_q])

    # Sohbeti kaydetme fonksiyonu
    def save_chat_to_file(chat_history):
        if not chat_history:
            return None
        
        # Chat geÃ§miÅŸini bir dosyaya kaydet
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"chat_history_{timestamp}.txt"
        
        with open(filename, "w") as file:
            file.write(chat_history)
        
        # KullanÄ±cÄ±ya dosya indirme baÄŸlantÄ±sÄ± gÃ¶nder
        return filename

    save_btn.click(fn=save_chat_to_file, inputs=[chatbox], outputs=download_file)

    # Soru gÃ¶nderme fonksiyonu
    def handle_question(user_question, total_questions, chat_history):
        # Soruyu kullanarak yanÄ±t al
        result = qa_chain.run(user_question)
        
        # GeÃ§miÅŸi gÃ¼ncelle ve toplam soru sayÄ±sÄ±nÄ± arttÄ±r
        chat_history = f"""
        <div style="background-color:#e8f4f8; padding: 10px; border-radius: 15px; margin-bottom: 5px;">
            <b>Soru:</b> <span style="color: black;">{user_question}</span>
        </div>
        <div style="background-color:#f1f9f5; padding: 10px; border-radius: 15px; margin-bottom: 5px;">
            <b>Cevap:</b> <span style="color: black;">{result}</span>
        </div>
        """ + chat_history  # Yeni soru-cevap en Ã¼stte

        total_questions += 1
        return chat_history, total_questions

    # GÃ¶nder butonuna tÄ±klanÄ±nca soru gÃ¶nderme iÅŸlemi
    send_btn.click(fn=handle_question, inputs=[user_input, total_q, chatbox], 
                   outputs=[chatbox, total_q])

# Gradio UI'sini baÅŸlatma
demo.launch(share=True)
